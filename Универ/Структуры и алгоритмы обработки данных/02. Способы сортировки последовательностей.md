**Сортировка** - это перемещение элементов последовательности в порядке возрастания (неубывания) или убывания (невозрастания)  
Области применения задачи сортировки:
1. Задача группировки
2. Поиск общих элементов в 2 или более последовательностях
3. Задача поиска
  
Задача: необходимо упорядочить $N$ записей $R_1$, $R_2$, $...$, $R_N$. Пусть каждая запись $R_i$ имеет ключ $k_i$, который и управляет процессом сортировки (в дальнейшем будем сортировать только ключи). Введем на множестве ключей отношение порядка $<$, такое, что для любых 3 значений ключа $a, b, c$ выполняются 2 условия:
1. Существует одно и только одно утверждение: либо $a < b$, либо $b < a$, либо $a=b$ (закон трихотомии)
2. Если $a < b$, а $b < c$, то из этого следует, что $a < c$ (закон транзитивности)  
  
Любое множество с данным отношением подлежит сортировке в выбранном нами смысле. Т. е. записи упорядочиваются в ряд $R_{i1}, R_{i2}, ..., R_{in}$, где $k_{i1}≤k_{i2}≤k_{in}$.  
## Сложность алгоритма

Скорость выполнения некоторой программы во многом зависит от быстродействия компьютера. Но даже на самом быстром компьютере одни программы будут работать быстро, а другие либо медленно, либо вообще не выдавать результат за адекватное время. Это связано не с производительностью техники, а со сложностью алгоритма. Под сложностью понимается количество элементарных операций (шагов цикла), которые будут выполнены с исходными данными размером $n$.  
Например, если для решения задачи используются 2 цикла, один из которых вложен в другой, каждый цикл производит $n$ итераций, а тело цикла выполняется всегда за некоторое константное время $C$, то время на выполнение будет пропорционально $C*n^2$. При малых $n$ константа $C$ играет существенное значение. Но чем больше $n$, тем значение константы $C$ уменьшается. Поэтому при оценке сложностей все подобные константы не учитываются. Сложность оценивается сверху (хуже чего не будет) и это описывается О-символикой: $O(f(n))$.  
## Базовые методы сортировки массивов
Среди методов сортировки массивов выделяют 3 базовых:
- Метод прямого включения
- Метод прямого выбора
- Метод прямого обмена
#### Метод прямого выбора
Среди всех элементов ищется минимальный и меняется местами с первым. Далее минимальный ищется среди оставшихся. и меняется местами со вторым. И т. д.
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void selection(int* m, int n) {
	for (int i = 0; i < n - 1; i++) {
		int min = m[i], index = i;
		for (int j = i + 1; j < n - 1; j++)
			if (m[j] < min) min = m[j], index = j;
		m[index] = m[i];
		m[i] = min;
	}
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	selection(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
Сложность метода - на любом массиве будет $O(n^2)$, т. к. в методе 2 вложенных цикла: первый проходит $n-1$ итерацию, внутренний - $n-1, n-2, ...$ итераций. 
#### Метод прямого включения (метод вставки)
$i$-тый элемент вставляется среди предыдущих на подходящее для него место. Эта процедура проводится для всех элементов массива, начиная со второго и до последнего:
```
1) 4
	10, 10, ...
	4, 10, ...
2) 55
	4, 10, 55, ...
3) 66
	4, 10, 55, 66, ...
4) 4
	4, 10, 55, 66, 66, ...
	4, 10, 55, 55, 66, ...
	4, 10, 10, 55, 66, ...
	4, 4, 10, 55, 66, ...
И т. д.
```
  
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void insertion(int* m, int n) {
	for (int i = 1; i < n; i++) {
		int x = m[i], j = i;
		while (j != 0 && x < m[j - 1]) m[j] = m[j - 1], j--;
		m[j] = x;
	}
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	insertion(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
В худшем случае, как и в среднем, сложность $O(n^2)$ из-за цикла в цикле. Однако в лучшем случае (уже отсортированный массив) сложность $O(n)$, т. к. тело цикла while не будет выполняться ни разу. 
#### Метод прямого обмена (метод пузырька)
Последний элемент массива сравнивается с предпоследним и если последний меньше, они меняются местами. Предпоследний элемент массива сравнивается с третьим с конца и снова упорядочивается. И т. д. до начала массива. В результате на 1 месте окажется минимальный элемент. Процедура повторяется, но движемся до 2, 3, ... элементов.  
Алгоритм называется методом пузырька, т. к. если представить массив вертикальным, то элементы, имеющие меньшие значения, на каждом проходе, как легкие пузырьки в воде, поднимаются вверх.
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void bubble(int* m, int n) {
	for (int i = 0; i < n - 1; i++) {
		for (int j = n-1; j>i; j--)
			if (m[j] < m[j-1]) swap(m[j], m[j-1]);
	}
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	bubble(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
2 вложенных цикла for дают сложность на любом входном массиве $O(n^2)$. Среди 3 базовых методов этот самый медленный.
## Улучшенные методы сортировки массивов
#### Шейкерная сортировка
Данный метод является улучшением метода пузырька:
1. Запоминать, были или нет перестановки в процессе некоторого прохода. Если не было - сортировку можно завершить
2. Запоминать не только сам факт перестановки, но и место последнего обмена. Ясно, что после этого места массив уже отсортирован.
3. Проводить сортировку последовательно в 2 направлениях по массиву - сначала от конца к началу, а затем от начала к концу
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void shaker(int* m, int n) {
	int left = 0, right = n - 1, k = right;
	do {
		for (int j = right; j >= left; j--)
			if (m[j] < m[j - 1]) {
				swap(m[j], m[j - 1]);
				k = j;
			}
		left = k + 1;

		for (int j = left; j <= right; j++)
			if (m[j] < m[j - 1]) {
				swap(m[j], m[j - 1]);
				k = j;
			}
		right = k - 1;
	} while (left <= right);
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	shaker(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
В лучшем случае на уже отсортированном массиве сложность будет $O(n)$, т. к. будет выполнен 1 раз первый цикл for, после чего **left** станет равным **right**. Однако в худшем случае (массив отсортирован в обратном порядке) сложность все равно будет $O(n^2)$.
#### Сортировка Шелла
Сначала отдельно группируются и сортируются элементы, отстоящие друг от друга на расстоянии $n/2$. Затем на расстоянии $n/4$ и так далее, пока не дойдем до обычной одинарной сортировки. На каждом проходе сортировка программируется как сортировка вставками, поэтому если какая-то последовательность уже отсортирована, происходит переход в следующий.

10, 4, 55, 66, 4, 123, 12, 666
<span style="color:#ff0000">4</span>, <span style="color:#00b050">4</span>, <span style="color:#ffff00">12</span>, 66, <span style="color:#ff0000">10</span>, <span style="color:#00b050">123</span>, <span style="color:#ffff00">55</span>, 666
<span style="color:#ff0000">4</span>, <span style="color:#00b050">4</span>, <span style="color:#ff0000"><span style="color:#ffff00">12</span></span>, 66, <span style="color:#ff0000">10</span>, <span style="color:#00b050">123</span>, <span style="color:#ffff00">55</span>, 666