**Фрэнк Розенблатт** (1928-1971) - известный американский ученый в области психологии, нейрофизиолог ИИ.  
![Фрэнк Розенблатт](../Pictures/04_01.%20Фрэнк%20Розенблатт.png)  
**Искусственная нейронная сеть (ИНС)** - математическая модель, а также ее программное или аппаратное воплощение, построенная по принципу организации и функционирования биологических нейронных сетей - сетей нервных клеток живого организма.
## Сепарабельность
- Линейно разделимые  
	![Линейно разделимые](../Pictures/04_02.%20Линейно%20разделимые.png)
- Линейно неразделимые  
	![Линейно неразделимые](../Pictures/04_03.%20Линейно%20неразделимые.png)
  
Простейшая нейронная сеть - **перцептрон Розенблатта** (1957).  
![Перцептрон Розенблата](../Pictures/04_04.%20Перцептрон%20Розенблата.png)  
Поступление сигналов с сенсорного поля в решающие блоки элементарного перцептрона в его физическом воплощении:  
![Поступление сигналов](../Pictures/04_05.%20Поступление%20сигналов.png)
## Модель обучения Розенблата - метод коррекции ошибки
Допустим, мы хотим обучить перцептрон разделять 2 класса объектов так, чтобы при предъявлении объектов 1 класса выход перцептрона был положителен (`+1`), а при предъявлении объектов 2 класса - отрицательным (`-1`). Для этого выполним следующий алгоритм:
1. Случайным образом выбираем пороги для $A$-элементов и устанавливаем связи $S-A$ (далее они изменяться не будут)
2. Начальные коэффициенты $w_i$ полагаем равными нулю
3. Предъявляем **обучающую выборку**: объекты (например, круги либо квадраты) с указанием класса, к которым они принадлежат
4. Показываем перцептрону объект 1 класса. При этом некоторые $A$-элементы возбудятся. Коэффициенты $w_i$, соответствующие этим возбужденным элементам, **увеличиваем** на 1
5. Показываем перцептрону объект 2 класса и коэффициенты $w_i$ тех $A$-элементов, которые возбудятся при этом показе, **уменьшаем** на 1
6. Обе части шага 3 выполним для всей обучающей выборки. В результате обучения сформируются значения весов связей $w_i$
#### Математическая реализация алгоритма
0. Начальные установки: веса $w_1(1)$, $w_2(1)$ и порог $T$ задаются случайным образом. Введем шаг обучения $t$: $t=0$
1. Примем $t=t+1$. Предъявим сети входной сигнал $x_1(t)$, $x_2(t)$. Пусть $d(t)=1$, если входной сигнал принадлежит классу $А$; $d(t)=-1$, если входной сигнал принадлежит классу $Б$
2. Вычислим состояние нейрона в момент времени $t$: $s(t)=w_1(t)x_1(t)+w_2(t)x_2(t)-T$
3. Вычислим выходной сигнал нейрона $y(t)$ в момент времени $t$: $y(t)=sign(s(t))$
4. Вычислим новые веса по формулам: $w_1(t)=w_1(t-1)+r(y(t)-d(t))$, $w_2(t)=w_2(t-1)+r(y(t)-d(t))$, где $r$ - шаг обучения
5. Если $r$ меньше объема обучающей выборки $L$, то переходим к шагу 1. В противном случае обучение заканчивается. Обучение также может закончиться, если веса не изменяются
  
Наиболее часто используемые функции активации в **методе обратного распространения ошибки**:
- $f(\frac{1}{1+e^{-2\alpha s}})$ - экспоненциальная сигмоида
- $f(s)=\frac{s}{|s|+\alpha}$ - рациональная сигмоида
- $f(s)=th(\frac{s}{\alpha})=\frac{e^\frac{s}{\alpha}-e^{-\frac{s}{\alpha}}}{e^\frac{s}{\alpha}+e^{-\frac{s}{\alpha}}}$ - гиперболический тангенс
  
где $s$ - выход сумматора нейрона, $\alpha$ - произвольная константа