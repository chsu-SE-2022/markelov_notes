<html>
   <head>
      <title> артинки</title>
   </head>

   <body background="песок.jpg">
      <img src="кот.jpg" weight="500" height="333" align="right" hspace="20" vspace="20" title=" от" border=12>
      <p align="justify">&nbsp;&nbsp;&nbsp;ѕредметом исследовани€ €вл€ютс€ формулы  . Ўеннона дл€ вычислени€ количества информации в сообщени€х дискретного источника и его энтропии, а также простейшие модели дискретных источников.÷ель работы Ц исследование свойств энтропии как количественной меры неопределенности дискретного источника. ¬ ходе работы требуетс€ произвести теоретические исследовани€ энтропии, а также численное <img src="Ћенин.svg" align="center" weight="250" height="125" title="Ћенин" hspace="20" vspace="20"> моделирование простейших дискретных стационарных и нестационарных источников. ќтчет по лабораторной работе выполнить на основе данного преподавателем шаблона и оформить согласно требовани€м √ќ—“ 7.32-2001 Ђќтчет о научно-исследовательской работе. —труктура и правила оформлени€ї</p>
      <p align="left">&nbsp;&nbsp;&nbsp;смоделировать дискретный нестационарный источник и построить гистограмму значений энтропии при прин€тии определенной серии сообщений (за множество сообщений вз€ть множество различных букв в вашем ‘»ќ + символ ђ"_" в качестве разделител€ слов; прописные и строчные не различать; веро€тности вычислить по частотам вхождени€ букв в ‘»ќ; при моделировании предположить, что источник по буквам формирует в точности ваше ‘»ќ; проинтерпретировать динамику изменени€ энтропии).</p>
      <img src="кот2.jpg" weight="460" height="225" align="left" hspace="20" vspace="20" title=" от" border=12>
      <p align="center">&nbsp;&nbsp;&nbsp;ѕон€тие информации предполагает наличие двух объектов: источника информации и потребител€ [1, 2]. »нформаци€ представл€етс€ в виде специальных знаков, символов; характерным носителем информации €вл€етс€ сообщение, под которым обычно понимают все то, что подлежит передаче. —татистический подход к оценке качества информации представлен в обширном разделе кибернетики Ц теории информации, котора€ занимаетс€ математиђческим описанием и оценкой методов передачи, хранени€, извлечеђни€ и классификации информации.ќсновы теории информации были заложены в 1948 г. американским математиком  . Ўенноном, который ввел пон€тие энтропии как меры неопределенности источника и количества информации через изменение этой неопределенности.ѕусть имеетс€ дискретный источник, заданный ансамблем сообщений X = {x1, x2, Е xN} и веро€тност€ми формировани€ этих сообщений P = {p1, p2, Е pN}. ¬ силу свойств ансамбл€, сообщени€ множества X €вл€ютс€ несовместными событи€ми</p>
      <p align="right">&nbsp;&nbsp;&nbsp;ћалые значени€ энтропии источника говор€т о его малой информативности; большие Ц о неопределенности того, какое именно сообщение будет сформировано источником в определенный момент. «начение энтропии в битах определ€ет минимальный размер двоичного кода (на одно сообщение в среднем), необходимого дл€ взаимнооднозначного кодировани€ сообщений источника. ÷елью данной лабораторной работы €вл€етс€ исследование свойств энтропии, предложенной Ўенноном, как количественной меры неопределенности дискретного источника. ќформление отчета по лабораторной работе было выполнено согласно требовани€м √ќ—“ 7.32Ц2001 Ђќтчет о научно-исследовательской работе. —труктура и правила оформлени€ї.</p>
      <marquee direction="up"><font color="Red">јјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјја</font></marquee>
      <marquee><img src="Ћенин.svg" weight="200" height="150" title="Ћенин" hspace="20" vspace="20"></marquee>
      
      <marquee direction="right"><font color="Red">јјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјјја</font></marquee>
      <marquee direction="down"><img src="загрузка.gif" weight="200" height="150" title="«агрузка" hspace="20" vspace="20"></marquee>
   </body>
</html>