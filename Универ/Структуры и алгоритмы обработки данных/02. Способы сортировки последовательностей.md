**Сортировка** - это перемещение элементов последовательности в порядке возрастания (неубывания) или убывания (невозрастания)  
Области применения задачи сортировки:
1. Задача группировки
2. Поиск общих элементов в 2 или более последовательностях
3. Задача поиска
  
Задача: необходимо упорядочить $N$ записей $R_1$, $R_2$, $...$, $R_N$. Пусть каждая запись $R_i$ имеет ключ $k_i$, который и управляет процессом сортировки (в дальнейшем будем сортировать только ключи). Введем на множестве ключей отношение порядка $<$, такое, что для любых 3 значений ключа $a, b, c$ выполняются 2 условия:
1. Существует одно и только одно утверждение: либо $a < b$, либо $b < a$, либо $a=b$ (закон трихотомии)
2. Если $a < b$, а $b < c$, то из этого следует, что $a < c$ (закон транзитивности)  
  
Любое множество с данным отношением подлежит сортировке в выбранном нами смысле. Т. е. записи упорядочиваются в ряд $R_{i1}, R_{i2}, ..., R_{in}$, где $k_{i1}≤k_{i2}≤k_{in}$.  
## Сложность алгоритма

Скорость выполнения некоторой программы во многом зависит от быстродействия компьютера. Но даже на самом быстром компьютере одни программы будут работать быстро, а другие либо медленно, либо вообще не выдавать результат за адекватное время. Это связано не с производительностью техники, а со сложностью алгоритма. Под сложностью понимается количество элементарных операций (шагов цикла), которые будут выполнены с исходными данными размером $n$.  
Например, если для решения задачи используются 2 цикла, один из которых вложен в другой, каждый цикл производит $n$ итераций, а тело цикла выполняется всегда за некоторое константное время $C$, то время на выполнение будет пропорционально $C*n^2$. При малых $n$ константа $C$ играет существенное значение. Но чем больше $n$, тем значение константы $C$ уменьшается. Поэтому при оценке сложностей все подобные константы не учитываются. Сложность оценивается сверху (хуже чего не будет) и это описывается О-символикой: $O(f(n))$.  
## Методы сортировки массивов
Среди методов сортировки массивов выделяют 3 базовых:
- Метод прямого включения
- Метод прямого выбора
- Метод прямого обмена
#### Метод прямого выбора
Среди всех элементов ищется минимальный и меняется местами с первым. Далее минимальный ищется среди оставшихся. и меняется местами со вторым. И т. д.
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void selection(int* m, int n) {
	for (int i = 0; i < n - 1; i++) {
		int min = m[i], index = i;
		for (int j = i + 1; j < n - 1; j++)
			if (m[j] < min) min = m[j], index = j;
		m[index] = m[i];
		m[i] = min;
	}
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	selection(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
Сложность метода - на любом массиве будет $O(n^2)$, т. к. в методе 2 вложенных цикла: первый проходит $n-1$ итерацию, внутренний - $n-1, n-2, ...$ итераций. 
#### Метод прямого включения (метод вставки)
$i$-тый элемент вставляется среди предыдущих на подходящее для него место. Эта процедура проводится для всех элементов массива, начиная со второго и до последнего:
```
1) 4
	10, 10, ...
	4, 10, ...
2) 55
	4, 10, 55, ...
3) 66
	4, 10, 55, 66, ...
4) 4
	4, 10, 55, 66, 66, ...
	4, 10, 55, 55, 66, ...
	4, 10, 10, 55, 66, ...
	4, 4, 10, 55, 66, ...
И т. д.
```
  
```cpp
#include <iostream>
#include <fstream>
using namespace std;

void insertion(int* m, int n) {
	for (int i = 1; i < n; i++) {
		int x = m[i], j = i;
		while (j != 0 && x < m[j - 1]) m[j] = m[j - 1], j--;
		m[j] = x;
	}
}

void main() {
	const int n = 10;
	int a[n] = { 10, 4, 55, 66, 4, 123, 12, 666, 3, -1 };
	insertion(a, n);
	for (int i = 0; i < n; i++)
		cout << a[i] << ' ';
	cout << endl;
	system("pause");
}
```
В худшем случае, как и в среднем, сложность $O(n^2)$ из-за цикла в цикле. Однако в лучшем случае уже отсортированный массив, т. к. тело цикла while не будет выполняться ни разу. 
#### Метод прямого обмена (метод пузырька)
Последний элемент массива сравнивается с предпоследним и если последний меньше